{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c6621f-5919-4113-9a39-fe2677dd19b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yasserali/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a823ca42-7f94-41d6-92e6-ef8f0aea7e07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.08540, saving model to best_model.keras\n",
      "750/750 - 9s - 12ms/step - accuracy: 0.9327 - loss: 0.2157 - val_accuracy: 0.9720 - val_loss: 0.0854\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 2: val_loss improved from 0.08540 to 0.05688, saving model to best_model.keras\n",
      "750/750 - 8s - 11ms/step - accuracy: 0.9823 - loss: 0.0569 - val_accuracy: 0.9841 - val_loss: 0.0569\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 3: val_loss improved from 0.05688 to 0.04804, saving model to best_model.keras\n",
      "750/750 - 1035s - 1s/step - accuracy: 0.9869 - loss: 0.0408 - val_accuracy: 0.9858 - val_loss: 0.0480\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 4: val_loss improved from 0.04804 to 0.04258, saving model to best_model.keras\n",
      "750/750 - 1972s - 3s/step - accuracy: 0.9904 - loss: 0.0299 - val_accuracy: 0.9886 - val_loss: 0.0426\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.04258\n",
      "750/750 - 607s - 810ms/step - accuracy: 0.9919 - loss: 0.0256 - val_accuracy: 0.9854 - val_loss: 0.0508\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.04258\n",
      "750/750 - 9s - 12ms/step - accuracy: 0.9935 - loss: 0.0197 - val_accuracy: 0.9878 - val_loss: 0.0434\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.04258\n",
      "750/750 - 9s - 12ms/step - accuracy: 0.9940 - loss: 0.0180 - val_accuracy: 0.9883 - val_loss: 0.0432\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.04258\n",
      "750/750 - 9s - 12ms/step - accuracy: 0.9954 - loss: 0.0135 - val_accuracy: 0.9870 - val_loss: 0.0489\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.04258\n",
      "750/750 - 8s - 11ms/step - accuracy: 0.9956 - loss: 0.0129 - val_accuracy: 0.9883 - val_loss: 0.0477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16c33ad10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "checkpoint = ModelCheckpoint('best_model.keras',\n",
    "                             monitor = 'val_loss',\n",
    "                             save_best_only = True,\n",
    "                             mode = 'min',\n",
    "                             verbose = 1)\n",
    "\n",
    "early_stopping = EarlyStopping(patience = 5, restore_best_weights = True)\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels,\n",
    "          validation_split = 0.2, \n",
    "          epochs = 30, \n",
    "          batch_size = 64, \n",
    "          verbose = 2,\n",
    "          callbacks = [checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a59521-a936-46b5-883a-77bb6748cf12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9864 - loss: 0.0416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03229127824306488, 0.989799976348877]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('best_model.keras')\n",
    "yhat = model.predict(test_images)\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e28b2ce-c2ac-40ae-97f3-d2fdd5c78cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(32, activation = 'relu'))\n",
    "model2.add(layers.Dropout(0.4))\n",
    "model2.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "121c6e85-e77d-4297-ba69-73e6be3fa1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.07636, saving model to best_model.keras\n",
      "750/750 - 9s - 12ms/step - accuracy: 0.8756 - loss: 0.3934 - val_accuracy: 0.9757 - val_loss: 0.0764\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 2: val_loss improved from 0.07636 to 0.05355, saving model to best_model.keras\n",
      "750/750 - 8s - 11ms/step - accuracy: 0.9546 - loss: 0.1508 - val_accuracy: 0.9839 - val_loss: 0.0536\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 3: val_loss improved from 0.05355 to 0.04900, saving model to best_model.keras\n",
      "750/750 - 8s - 11ms/step - accuracy: 0.9649 - loss: 0.1134 - val_accuracy: 0.9862 - val_loss: 0.0490\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 4: val_loss improved from 0.04900 to 0.04396, saving model to best_model.keras\n",
      "750/750 - 9s - 11ms/step - accuracy: 0.9705 - loss: 0.0948 - val_accuracy: 0.9877 - val_loss: 0.0440\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.04396\n",
      "750/750 - 9s - 12ms/step - accuracy: 0.9757 - loss: 0.0777 - val_accuracy: 0.9850 - val_loss: 0.0549\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.04396\n",
      "750/750 - 9s - 12ms/step - accuracy: 0.9805 - loss: 0.0647 - val_accuracy: 0.9877 - val_loss: 0.0496\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 7: val_loss improved from 0.04396 to 0.04360, saving model to best_model.keras\n",
      "750/750 - 9s - 11ms/step - accuracy: 0.9813 - loss: 0.0579 - val_accuracy: 0.9894 - val_loss: 0.0436\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.04360\n",
      "750/750 - 9s - 11ms/step - accuracy: 0.9840 - loss: 0.0529 - val_accuracy: 0.9871 - val_loss: 0.0510\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 9: val_loss improved from 0.04360 to 0.04348, saving model to best_model.keras\n",
      "750/750 - 9s - 12ms/step - accuracy: 0.9851 - loss: 0.0472 - val_accuracy: 0.9899 - val_loss: 0.0435\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.04348\n",
      "750/750 - 11s - 15ms/step - accuracy: 0.9849 - loss: 0.0465 - val_accuracy: 0.9900 - val_loss: 0.0468\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.04348\n",
      "750/750 - 9s - 12ms/step - accuracy: 0.9879 - loss: 0.0382 - val_accuracy: 0.9898 - val_loss: 0.0451\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.04348\n",
      "750/750 - 10s - 13ms/step - accuracy: 0.9867 - loss: 0.0405 - val_accuracy: 0.9903 - val_loss: 0.0468\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.04348\n",
      "750/750 - 10s - 13ms/step - accuracy: 0.9887 - loss: 0.0334 - val_accuracy: 0.9904 - val_loss: 0.0493\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.04348\n",
      "750/750 - 9s - 12ms/step - accuracy: 0.9890 - loss: 0.0330 - val_accuracy: 0.9896 - val_loss: 0.0473\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9864 - loss: 0.0416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03229127824306488, 0.989799976348877]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint('best_model.keras',\n",
    "                             monitor = 'val_loss',\n",
    "                             save_best_only = True,\n",
    "                             mode = 'min',\n",
    "                             verbose = 1)\n",
    "\n",
    "early_stopping = EarlyStopping(patience = 5, restore_best_weights = True)\n",
    "\n",
    "model2.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model2.fit(train_images, train_labels,\n",
    "          validation_split = 0.2, \n",
    "          epochs = 30, \n",
    "          batch_size = 64, \n",
    "          verbose = 2,\n",
    "          callbacks = [checkpoint, early_stopping])\n",
    "\n",
    "model2.load_weights('best_model.keras')\n",
    "yhat = model2.predict(test_images)\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90457c0c-5125-4c32-b6a1-391dde89094f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03294499218463898, 0.9909999966621399]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model2.predict(test_images)\n",
    "model2.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb83831-064d-4f3b-ba29-18a62004319f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
